{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Finetuning the Seamless M4T Model on Romanian Common Voice\n",
    "## Import Libraries and Prepare Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f11b2067c5c46cab05860e751344c2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install transformers datasets evaluate\n",
    "\n",
    "# Import required libraries\n",
    "from transformers import AutoProcessor, SeamlessM4Tv2Model, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from huggingface_hub import notebook_login\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "# Log into the Hugging Face Hub\n",
    "notebook_login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T15:47:22.460048100Z",
     "start_time": "2024-05-09T15:47:20.243559900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and Preprocess the Romanian Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\afrca\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\mozilla-foundation--common_voice_13_0\\2506e9a8950f5807ceae08c2920e814222909fd7f477b74f5d225802e9f04055 (last modified on Tue May  7 21:00:21 2024) since it couldn't be found locally at mozilla-foundation/common_voice_13_0, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\afrca\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\mozilla-foundation--common_voice_13_0\\2506e9a8950f5807ceae08c2920e814222909fd7f477b74f5d225802e9f04055 (last modified on Tue May  7 21:00:21 2024) since it couldn't be found locally at mozilla-foundation/common_voice_13_0, or remotely on the Hugging Face Hub.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69555ff14ab8447d95fb6c3888d7a71b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/8949 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad0d4c0fb4a14fe592bb07539111a167"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3861 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2516f915e72a4407a11c597c7fe9be39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the Romanian Common Voice dataset\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"ro\", split=\"train+validation\")\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"ro\", split=\"test\")\n",
    "\n",
    "# Initialize the processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
    "model = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
    "\n",
    "# Find the appropriate sampling rate for the model\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "\n",
    "# Cast audio to the correct sampling rate using the `datasets` Audio feature\n",
    "from datasets import Audio\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "\n",
    "# Define a data preparation function\n",
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "    example = processor(\n",
    "        audios=audio[\"array\"],\n",
    "        sampling_rate=sampling_rate,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# Apply the data preparation function to the entire dataset\n",
    "common_voice = common_voice.map(prepare_dataset, remove_columns=[\"client_id\", \"path\", \"up_votes\", \"down_votes\", \"age\", \"gender\", \"accent\", \"locale\", \"segment\", \"variant\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:10:10.297243500Z",
     "start_time": "2024-05-09T15:51:59.677415400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define a Data Collator and Evaluation Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Define the data collator\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # Separate input features and labels for independent processing\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"][0]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "# Initialize the data collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor)\n",
    "\n",
    "# Load and define the WER evaluation metric\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "# Define the function to compute metrics\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    return {\"wer\": metric.compute(predictions=pred_str, references=label_str)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:10:14.690391600Z",
     "start_time": "2024-05-09T16:10:13.145102900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure Training and Launch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "# print torch device\n",
    "print(\"test\")\n",
    "#\n",
    "# # Define training arguments\n",
    "# training_args = Seq2SeqTrainingArguments(\n",
    "#     output_dir=\"./seamless-m4t-ro\",\n",
    "#     per_device_train_batch_size=8,\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     learning_rate=1e-5,\n",
    "#     num_train_epochs=5,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     eval_steps=100,\n",
    "#     save_steps=100,\n",
    "#     logging_steps=50,\n",
    "#     report_to=[\"tensorboard\"],\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"wer\",\n",
    "#     greater_is_better=False,\n",
    "#     push_to_hub=True\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:21:31.545963400Z",
     "start_time": "2024-05-09T16:21:31.538116100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
